# CICD shell

## AD permissions

The permissions to target machines and perform actions are realized through our Active directory.
As an example to access the machines of the `middleware` hostgroup, you will need to be part of the `GP_APP_SALT_MIDDLEWARE` group.

Please fill in a `irisline` ticket to get the necessary permissions.

## Usage

### command line

The name of the command line utility is #cicd#. The first mandatory position argument is the zone (dev, testing, staging or prod).

The #stack# command subgroup would hit nodes inside a specific stack. You can specify the stack by using the `-s` option but by default when none is provided the https://github.com/CIRB/devbox/blob/master/user/params.sh[default stack of the devbox] is used.

The #node# command subgroup always target a specific node.

Here are some examples:

```
→ cicd prod stack facts
→ cicd prod stack facts jenkins.slave
→ cicd prod stack data docker::version
→ cicd prod stack runpuppet saltmaster
→ cicd prod node facts svappcavl771.prd.srv.cirb.lan
→ cicd prod node data svappcavl771.prd.srv.cirb.lan
→ cicd staging node du svappcavl703.sta.srv.cirb.lan <1>
→ cicd staging node runpuppet svappcavl703.sta.srv.cirb.lan
→ cicd testing result -n 2
```
<1> `du` stands for disk usage

NOTE: you can always specify another stack
You can request the help at each level. For instance:
```
→ cicd -h <1>
→ cicd staging stack
→ cicd staging stack facts -h
→ cicd staging result
```
<1> you can omit `-h` (when the command is invalid it automatically displays the help)


[NOTE]
- These commands are executed remotely (if you have the right to execute them) through an API. Behind the scene they might call either the `puppetdb` or the `saltmaster`. For instance `cicd ZONE node facts NODE` would call the puppetdb and return a result even when the node is down.

- All commands to the saltmaster together with their results are recorded in a centralize database included the date and name of the person that execute them.


### The specialized shell

.Open a specialized #console in staging#
```
→ cicd staging console
```

One great feature of this specialized shell is the *automatic completion* (while typing) of the available nodes, commands, ... It acts as an interactive help to ease the task at hand.

#### examples

- Summary of all machines and a selection of interesting facts about them:
```
$ stack_facts
{
  "fqdn": "svappcavl703.sta.srv.cirb.lan",
  "ip": "192.168.22.250",
  "os": "CentOS 7.2.1511",
  "subgroup": "",
  "role": "saltmaster"
}
```

- Run puppet via the `pep` alias on two nodes:
```
pep -L foreman.sandbox.srv.cirb.lan,puppetdb.sandbox.srv.cirb.lan --client=local_async puppetutils.run_agent
```

- Disk usage on a node:
```
$ node_du svappcavl088.sta.srv.cirb.lan
{
  "svappcavl088.sta.srv.cirb.lan": {
    "/": "23%",
    "/boot": "69%",
    "/data": "51%",
    "/dev/shm": "1%",
    "/home": "19%",
    "/tmp": "35%",
    "/usr": "44%",
    "/var": "74%",
    "/var/log": "4%"
  }
}
```

#### available commands

* `stack_ping`: ping all nodes within your stack
* `stack_ping_on` t : ping nodes by target t
* `stack_facts`: important facts on all machines within your stack
* `stack_facts_on` t : important facts about target t
* `stack_orch` c: launch the orchestration `c` command
* `stack_data_for` k : dynamic info given a specific key `k` across all nodes
* `stack_runpuppet_on` t : run puppet on target t
* `node_facts` n : all static information available on a specific node `n`
* `node_runpuppet` n: run puppet on a specific node `n`
* `node_data` n: dynamic info from hiera for a specific node `n`
* `node_du` n: disk usage on a node
* `result` [i] : result of your last `i` command(s)
* `result_for` jid: result of a specific job specified by its `jid`
* `commands`:  list all possible salt execution commands (slow)
* `stats`: status of all the nodes


## Orchestration

Salt can run multiple commands as well using the orchestrate runner. The orchestration is executed on the salt master to allow inter minion requisites, like ordering the application of states on different minions that must not happen simultaneously, or for halting the state run on all minions if a minion fails one of its states (more about this topic can be found https://docs.saltstack.com/en/latest/topics/tutorials/states_pt5.html#orchestrate-runner[in the saltstack website]).

The orchestration should be defined in the orch folder. You will find some examples http://stash.cirb.lan/projects/MIDDLEWARE/repos/salt-stack-middleware/browse/orch?at=refs%2Fheads%2Fmiddleware[here].

Orchestrate commands can be started using:

```
→ cicd testing orch CMD
```

## Install outside the devbox

To install the shell outside the devbox, the requirements are:

* OS: linux
* git
* nix

If you haven't installed `nix` already, here is the quick how to:

```
bash <(curl https://nixos.org/nix/install)
```
This will perform a single-user installation of Nix, meaning that /nix is owned by the invoking user. The script will only invoke `sudo` to create /nix if it doesn’t already exist. At that point, the script will prompt you for a password.

To activate `nix` in your shell, add the following line in your `.bash_profile`:

```
source ~/.nix-profile/etc/profile.d/nix.sh'
```

You will also need to fetch the `nixpkgs` source for https://github.com/CIRB/devbox/blob/master/user/config.nix including the `pkgs` folder.


## TODO

- [ ] in devbox, update `language-puppet`
- [ ] re-use cicd in the console (cicd prod stack ping -> stack ping)
- [ ] in devbox, insert this README
- [ ] use puppetdb instead of salt for stack_data_for
- [ ] improve zsh completion
